{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = ['Skull', 'Hourglass', 'Globe', 'Coins', 'Butterfly ', 'Flowers', 'Watch', 'Dice', 'Fruit', 'violin',\n",
    "                'Lute', 'Flute', 'Candle', 'Inkstand', 'Music', 'Bubble', 'Lamp', 'Book', 'Glass', 'Goblet', 'Vase',\n",
    "                'Crown', 'Bishop\\'s mitre', 'Bishop\\'s Mitre', 'Crab', 'Lobster', 'Seashells', 'Chicken', 'Atlas',\n",
    "                'Clock', 'Fish', 'Smoke', 'Bread', 'Wine', 'sea shells']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array, int32\n",
    "import json\n",
    "import os\n",
    "import numpy\n",
    "import sklearn\n",
    "\n",
    "src_dir = '/Users/gregorykell/Research/fine_art_project/fine_art_asssociations_meanings_nlp/data/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  with open('data/vision_outputs/vision_results_file.txt', 'r') as f:\n",
    "#     for line in f:\n",
    "#         if 'scores' in line or 'rois' in line:\n",
    "# #             print(line)\n",
    "# #             print(len(line.split('], [')))\n",
    "#             line = [l.split('], [') for l in line.split('], [')]\n",
    "            \n",
    "# #             print(line)\n",
    "#             for l in line:\n",
    "#                 print(l)\n",
    "#                 for el in l:\n",
    "#                     print(el)\n",
    "#             print(line[1])\n",
    "            \n",
    "#             try:\n",
    "#                 print(line[1])\n",
    "#             except:\n",
    "#                 pass\n",
    "#             print(line.split(':'))\n",
    "#     vision_results = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vision_results\n",
    "\n",
    "detections = [\n",
    "    {'img': '5aadcb7882.jpg', 'class_ids': [], 'scores': [] },\n",
    "    {'img': 'fed306f057.jpg', 'class_ids': [10], 'scores': [0.93937874]},\n",
    "    {'img': '8d4205809e.jpg', 'class_ids': [], 'scores': []},\n",
    "    {'img': '05d9284b10.jpg', 'class_ids': [1], 'scores': [0.9398588]},\n",
    "    {'img': '2424027234.jpg', 'class_ids': [], 'scores': []},\n",
    "    {'img': 'a861ea64fb.jpg', 'class_ids': [], 'scores': []},\n",
    "    {'img': '2424133048.jpg', 'class_ids': [21, 1], 'scores': [0.94296116, 0.90677196]},\n",
    "    {'img': 'c61e32741c.jpg', 'class_ids': [], 'scores': []},\n",
    "    {'img': '8ad536eb55.jpg', 'class_ids': [1], 'scores': [0.99696594]},\n",
    "    {'img': '86e7643246.jpg', 'class_ids': [1], 'scores': [0.9362383]},\n",
    "    {'img': 'd6c400594b.jpg', 'class_ids': [], 'scores': []},\n",
    "    {'img': 'd906904f4f.jpg', 'class_ids': [], 'scores': []},\n",
    "    {'img': '8862bd2fb0.jpg', 'class_ids': [1], 'scores': [0.91473407]},\n",
    "    {'img': 'fd87965987.jpg', 'class_ids': [1], 'scores': [0.9935489]},\n",
    "    {'img': 'a964dd4aef.jpg', 'class_ids': [1], 'scores': [0.96582496]},\n",
    "    {'img': 'db39fb81b1.jpg', 'class_ids': [], 'scores': []},\n",
    "    {'img': 'aa93e919ac.jpg', 'class_ids': [1], 'scores': [0.9751281]},\n",
    "    {'img': 'e624f5dfe2.jpg', 'class_ids': [], 'scores': []}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vision_results = vision_results.replace(\"'\", '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'img': '5aadcb7882.jpg', 'class_ids': [], 'scores': []},\n",
       " {'img': 'fed306f057.jpg', 'class_ids': [10], 'scores': [0.93937874]},\n",
       " {'img': '8d4205809e.jpg', 'class_ids': [], 'scores': []},\n",
       " {'img': '05d9284b10.jpg', 'class_ids': [1], 'scores': [0.9398588]},\n",
       " {'img': '2424027234.jpg', 'class_ids': [], 'scores': []},\n",
       " {'img': 'a861ea64fb.jpg', 'class_ids': [], 'scores': []},\n",
       " {'img': '2424133048.jpg',\n",
       "  'class_ids': [21, 1],\n",
       "  'scores': [0.94296116, 0.90677196]},\n",
       " {'img': 'c61e32741c.jpg', 'class_ids': [], 'scores': []},\n",
       " {'img': '8ad536eb55.jpg', 'class_ids': [1], 'scores': [0.99696594]},\n",
       " {'img': '86e7643246.jpg', 'class_ids': [1], 'scores': [0.9362383]},\n",
       " {'img': 'd6c400594b.jpg', 'class_ids': [], 'scores': []},\n",
       " {'img': 'd906904f4f.jpg', 'class_ids': [], 'scores': []},\n",
       " {'img': '8862bd2fb0.jpg', 'class_ids': [1], 'scores': [0.91473407]},\n",
       " {'img': 'fd87965987.jpg', 'class_ids': [1], 'scores': [0.9935489]},\n",
       " {'img': 'a964dd4aef.jpg', 'class_ids': [1], 'scores': [0.96582496]},\n",
       " {'img': 'db39fb81b1.jpg', 'class_ids': [], 'scores': []},\n",
       " {'img': 'aa93e919ac.jpg', 'class_ids': [1], 'scores': [0.9751281]},\n",
       " {'img': 'e624f5dfe2.jpg', 'class_ids': [], 'scores': []}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = ['Skull', 'Hourglass', 'Globe', 'Coins', 'Butterfly ', 'Flowers', 'Watch', 'Dice', 'Fruit', 'violin',\n",
    "                'Lute', 'Flute', 'Candle', 'Inkstand', 'Music', 'Bubble', 'Lamp', 'Book', 'Glass', 'Goblet', 'Vase',\n",
    "                'Crown', 'Bishop\\'s mitre', 'Bishop\\'s Mitre', 'Crab', 'Lobster', 'Seashells', 'Chicken', 'Atlas',\n",
    "                'Clock', 'Fish', 'Smoke', 'Bread', 'Wine', 'sea shells']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(detections)):\n",
    "    detections[i]['classes'] = []\n",
    "    for class_id in detections[i]['class_ids']:\n",
    "        detections[i]['classes'].append(keys[class_id-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'img': '5aadcb7882.jpg', 'class_ids': [], 'scores': [], 'classes': []},\n",
       " {'img': 'fed306f057.jpg',\n",
       "  'class_ids': [10],\n",
       "  'scores': [0.93937874],\n",
       "  'classes': ['violin']},\n",
       " {'img': '8d4205809e.jpg', 'class_ids': [], 'scores': [], 'classes': []},\n",
       " {'img': '05d9284b10.jpg',\n",
       "  'class_ids': [1],\n",
       "  'scores': [0.9398588],\n",
       "  'classes': ['Skull']},\n",
       " {'img': '2424027234.jpg', 'class_ids': [], 'scores': [], 'classes': []},\n",
       " {'img': 'a861ea64fb.jpg', 'class_ids': [], 'scores': [], 'classes': []},\n",
       " {'img': '2424133048.jpg',\n",
       "  'class_ids': [21, 1],\n",
       "  'scores': [0.94296116, 0.90677196],\n",
       "  'classes': ['Vase', 'Skull']},\n",
       " {'img': 'c61e32741c.jpg', 'class_ids': [], 'scores': [], 'classes': []},\n",
       " {'img': '8ad536eb55.jpg',\n",
       "  'class_ids': [1],\n",
       "  'scores': [0.99696594],\n",
       "  'classes': ['Skull']},\n",
       " {'img': '86e7643246.jpg',\n",
       "  'class_ids': [1],\n",
       "  'scores': [0.9362383],\n",
       "  'classes': ['Skull']},\n",
       " {'img': 'd6c400594b.jpg', 'class_ids': [], 'scores': [], 'classes': []},\n",
       " {'img': 'd906904f4f.jpg', 'class_ids': [], 'scores': [], 'classes': []},\n",
       " {'img': '8862bd2fb0.jpg',\n",
       "  'class_ids': [1],\n",
       "  'scores': [0.91473407],\n",
       "  'classes': ['Skull']},\n",
       " {'img': 'fd87965987.jpg',\n",
       "  'class_ids': [1],\n",
       "  'scores': [0.9935489],\n",
       "  'classes': ['Skull']},\n",
       " {'img': 'a964dd4aef.jpg',\n",
       "  'class_ids': [1],\n",
       "  'scores': [0.96582496],\n",
       "  'classes': ['Skull']},\n",
       " {'img': 'db39fb81b1.jpg', 'class_ids': [], 'scores': [], 'classes': []},\n",
       " {'img': 'aa93e919ac.jpg',\n",
       "  'class_ids': [1],\n",
       "  'scores': [0.9751281],\n",
       "  'classes': ['Skull']},\n",
       " {'img': 'e624f5dfe2.jpg', 'class_ids': [], 'scores': [], 'classes': []}]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_names = []\n",
    "label_paths = []\n",
    "\n",
    "for file in os.listdir(src_dir):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        file_names.append(file)\n",
    "    else:\n",
    "        label_paths.append(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_names.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = {}\n",
    "tags_seen = []\n",
    "\n",
    "for l_path in label_paths:\n",
    "    file_path = os.path.join(src_dir, l_path)\n",
    "#     print(file_path)\n",
    "    with open(file_path, 'r') as f:\n",
    "        l_data = json.load(f)\n",
    "#     print(l_data['asset']['name'])\n",
    "    tags = [item['tags'][0] for item in l_data['regions']]\n",
    "#     print(tags)\n",
    "    labels[l_data['asset']['name']] = tags\n",
    "    tags_seen = tags_seen + tags\n",
    "\n",
    "tags_seen = list(set(tags_seen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision_recall_curve(y_true, pred_scores, thresholds):\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    \n",
    "    if not y_true and not pred_scores:\n",
    "        \n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred = [\"positive\" if score >= threshold else \"negative\" for score in pred_scores]\n",
    "        \n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        FN = 0\n",
    "        for i in range(len(y_pred)):\n",
    "            if y_pred[i] == y_true[i]:\n",
    "                if y_pred[i] == 'positive':\n",
    "                    TP +=1\n",
    "#                 else:\n",
    "#                     TN +=1\n",
    "            elif y_pred[i] == 'positive':\n",
    "                FP +=1\n",
    "            else:\n",
    "                FN+=1\n",
    "                \n",
    "        if \n",
    "        \n",
    "        precision = TP/(FP + TP +1e-15)\n",
    "        recall = TP/(TP +FN +1e-15)\n",
    "\n",
    "#         precision = sklearn.metrics.precision_score(y_true=y_true, y_pred=y_pred, pos_label=\"positive\")\n",
    "#         recall = sklearn.metrics.recall_score(y_true=y_true, y_pred=y_pred, pos_label=\"positive\")\n",
    "        \n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "AP_list = []\n",
    "AR_list = []\n",
    "for tag in tags_seen:\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    pred_scores = []\n",
    "    thresholds=numpy.arange(start=0.2, stop=0.7, step=0.05)\n",
    "    weight = 0\n",
    "    for d in detections:\n",
    "        if tag in d['classes']:\n",
    "            y_pred.append(\"positive\")\n",
    "            ind = d['classes'].index(tag)\n",
    "            pred_scores.append(d['scores'][ind])\n",
    "        else:\n",
    "            y_pred.append('negative')\n",
    "            pred_scores.append(0)\n",
    "        \n",
    "        label = labels[d['img']]\n",
    "        if tag in label:\n",
    "            y_true.append('positive')\n",
    "            weight +=1\n",
    "        else:\n",
    "            y_true.append('negative')\n",
    "            \n",
    "    precisions, recalls = precision_recall_curve(y_true=y_true, \n",
    "                                             pred_scores=pred_scores, \n",
    "                                             thresholds=thresholds)\n",
    "\n",
    "    precisions.append(1)\n",
    "    recalls.append(0)\n",
    "\n",
    "    precisions = numpy.array(precisions)\n",
    "    recalls = numpy.array(recalls)\n",
    "    \n",
    "    AP = numpy.sum((recalls[:-1] - recalls[1:]) * precisions[:-1])\n",
    "    \n",
    "    AR = numpy.sum((-precisions[:-1] + precisions[1:]) * recalls[:-1])\n",
    "#     print(AR)\n",
    "    AP_list.append((AP, weight))\n",
    "    AR_list.append((AR, weight))\n",
    "\n",
    "     \n",
    "norm = sum([weight for _, weight in AP_list])\n",
    "\n",
    "mAP = np.mean([AP for AP, _ in AP_list])\n",
    "mAR = np.mean([AR for AR, _ in AR_list])\n",
    "weighted_mAP = sum( weight*AP for weight, AP in AP_list)/norm\n",
    "weighted_mAR = sum( weight*AR for weight, AR in AR_list)/norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017150673400673385"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046348314606741554"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted_mAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "\n",
    "for d in detections:\n",
    "    for tag in d['classes']:\n",
    "        if tag in labels[d['img']]:\n",
    "            TP +=1\n",
    "        else:\n",
    "            FP +=1\n",
    "        \n",
    "for key in labels.keys():\n",
    "    for tag in labels[key]:\n",
    "        for d in detections:\n",
    "            if d['img'] == key and tag not in d['classes']:\n",
    "                FN+=1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    }
   ],
   "source": [
    "precision = TP/(TP+FP)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05555555555555555\n"
     ]
    }
   ],
   "source": [
    "recall = TP/(TP+FN)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_f1(p, r):\n",
    "    return 2*p*r/(p+r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10169491525423728"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_f1(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/detections_objects.pkl', 'wb') as f:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fin_art_project",
   "language": "python",
   "name": "fin_art_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
